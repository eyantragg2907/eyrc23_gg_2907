1. Image Processing

We are detecting the four corners of the arena using cv2 AruCo detection. Then, we transform the frame (rotate and zoom)
and get the images using a specified offset from the near aruco markers. We are also doing a morphological transformation of the frame.
The events are being pre-preprocessed along the following - 
 - Pixel values are being scaled to 0-1
 - Images are being resized to 64 x 64 using bicubic interpolation

2. Event Detection

The images are then fed into a model to classify the images.
We are using a Convolutional Neural Network. Following is the architecture of the model:
    _________________________________________________________________
    Layer (type)                Output Shape              Param #   
    =================================================================
    sequential (Sequential)     (None, 32, 32, 64)        38720     
                                                                    
    sequential_1 (Sequential)   (None, 16, 16, 128)       221440    
                                                                    
    dropout (Dropout)           (None, 16, 16, 128)       0         
                                                                    
    sequential_2 (Sequential)   (None, 4, 4, 128)         819456    
                                                                    
    sequential_3 (Sequential)   (None, 1, 1, 256)         2458112   
                                                                    
    flatten (Flatten)           (None, 256)               0         
                                                                    
    dropout_1 (Dropout)         (None, 256)               0         
                                                                    
    batch_normalization (Batch  (None, 256)               1024      
    Normalization)                                                  
                                                                    
    dense (Dense)               (None, 1024)              263168    
                                                                    
    dense_1 (Dense)             (None, 1024)              1049600   
                                                                    
    dense_2 (Dense)             (None, 6)                 6150      
                                                                    
    =================================================================
    Total params: 4857670 (18.53 MB)
    Trainable params: 4857158 (18.53 MB)
    Non-trainable params: 512 (2.00 KB)
    _________________________________________________________________

3. Line Following
    We are using 5 IR sensors for the line following algorithm. 
    The robot has 2 modes - Line Following and Bang Bang

    Line Following is activated when any of the 3 middle IR sensors detect a black line. Otherwise, bang bang mode is activated.

    We have different types of operation, for starting the run, ending the run, rotating, reaching the node,etc. 

    In the Line Following mode, the middle IR is supposed to follow the black line. The 2nd and 4th IR sensors give the feedback required for this.
    In the Bang Bang mode, the extreme IRs are supposed to stay within the limits of the road. As soon as any of them detects a black line/grass,
    the robot moves in the other direction to stay on track.

    The entire Arduino Code is multithreaded to run the Wi-Fi module and the line following algorithm simultaneously on separate threads.
    
    A path is given to the robot in the Arduino Code which has the following keywords ->
    l -> left turn
    r -> right turn 
    x -> stop at event (destination for one call of djikstra) and do forward (this works 
            only when the computer calculates distance between robot and event and pings the robot to stop)
    n -> move forward at node 
    R -> take a U turn


4. Path Planning

We are using Djikstra algorithm for path planning. The algorithm is implemented in the file `dkistra.py`. 
The algorithm is implemented in the following steps:
1. We have given names to every node and event spot on the arena which are used for path planning.
2. The module maintains a constants.py that has the times the robot takes to move between nodes/events. Our naming convetion is used there.
   The module also maintains the priority orders.
3. The script is given a dictionary of the detected events at A, B, C, D, E.
4. The script path plans from the starting node to every event iteratively and generates a path string.
5. For the djikstra algorithm, the step space is same as the symbols defined in Line Following.
6. The returned path is sent to the ESP32 via Wi-Fi serial for movement.